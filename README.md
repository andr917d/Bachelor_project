Bachelor_project
==============================

This project investigates various neural network methods for uncertainty quantification, including Deterministic models, MC Dropout, Deep Ensembles, Bayesian Neural Networks (BNNs), Batch Ensembles, and Rank-1 BNNs. The models are evaluated on the MNIST, CIFAR-10, and Forest Cover datasets, focusing on metrics like Negative Log Likelihood, accuracy, expected calibration error, and parameter count. Key research questions address the effectiveness of Bayesian methods versus non-Bayesian methods in capturing uncertainty, the trade-offs between different models, and the robustness of these methods on out-of-distribution data.
